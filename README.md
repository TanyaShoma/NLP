In this project, we first built a GRU-based neural network to classify disaster-related tweets. The GRU model was chosen due to its efficiency in processing short sequences, like tweets. After conducting exploratory data analysis, we preprocessed the text data, tokenized it, and padded sequences to make them uniform. The GRU model demonstrated weak performance in classifying tweets, as evident from the validation results. Since the GRU model had low accuracy, we build a LSTM model for the text classification, however the LSTM model did not improve the classification performance compared to GRU. To futher improve the classification perforance we applied bidirectional LSTM which significantly improve the classification performance of disaster-related tweets compared to simpler models like GRU and standard LSTM. The achieved accuracy of 0.79, along with robust precision and recall metrics, leverage the effectiveness of using deep learning techniques in natural language processing tasks.

Future work could continue to boost the classification performance. hyperparameter tuning and data augmentation are good step for a better performance. Additionally, experimenting with transformer-based models, such as BERT, could also be beneficial in capturing the contextual intricacies of the data.
